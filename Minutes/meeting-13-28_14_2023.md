## Supervisor Meeting 13
**Date:** 28th July 2023

**Location:** Bayes Center Room 2.02

**Next meeting:** 7th August 

### Attendees:
* Dr Evgenij Belikov
* Daniil Kuznetsov

### Discussion:
* Discussed conclusions that can be drawn from the exploration results, more emphasis should be placed on the rate of performance increase from each reward feedback approach as well as change in graph style.
* Need for pseudorandom seed evaluation to provide as a review for the impact of randomness on agent performance, for the purposes of the project the seed is fixed throughout all experiments given that it has so far worked for majority of learning cases. However, that is not to say bad seeds that cause learning to fail do not exist.


### Previous Meeting Actions:
* Polish 'Background' section for review. (Will be addressed by next meeting)
* Scalability study on Cirrus GPU partition, as well as 24 hour performance training evaluation on a suitable configuration. (Done)
* Write the 'Conclusion' aspect of the report. (Will be addressed by next meeting, delayed in favour of Experimental Setup secton)
* Document learnt strategies by the agent. (Will be addressed by next meeting, delayed due to need for more emphasis on GPU evaluations)

### Actions:
* Finish Background and Experimental Setup write-up, leaving only the conclusion section left.
* Perform a multi-node strong scaling evaluation as part of multi-node experimentation, note that Cirrus GPU section already addresses this hence only ARCHER2 will be evaluated.
* Compile torch with CUDA 11.6 support, since newer versions of torch only support down to 11.7 but Cirrus hardware supports up to 11.6. Could explain the lack of benefit from CUDA graphs and mixed precision implementations.
* Document FullyConv GPU 24 hour experiment evaluation of performance and contrast with ARCHER2 results.

